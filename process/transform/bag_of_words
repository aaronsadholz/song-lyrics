#!/usr/bin/env python

"""
Parse musixmatch dataset in json format and output a Apache Feather file
where each row is a song and each column is the word count, also adds a column
for the track id. Optionally, cut the number of words to only output up to
the n-th most popular word.
"""
import logging
import argparse
import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
from song_lyrics.parse import load_json_data
from song_lyrics.transform import bow2vector


def main():
    # instantiate a logger to print useful information about the progress
    logger = logging.getLogger(__name__)

    # config logger to INFO level
    logging.basicConfig(level=logging.INFO)

    # use docstring at the top as description for the script
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument('path_to_data', type=str,
                        help='Path to the json data')
    parser.add_argument('path_to_output', type=str,
                        help='Output path for the feather file')
    parser.add_argument('--max_words', default=5000, type=int,
                        help='How many words to include (most popular)')
    parser.add_argument('--normalize', action='store_true',
                        help='Normalize counts by converting them to'
                             ' proportions')
    parser.add_argument('--keep_stopwords', action='store_true',
                        help='Keep stopwords')

    args = parser.parse_args()
    path_to_data = args.path_to_data
    path_to_output = (args.path_to_output
                      if args.path_to_output.endswith('.feather')
                      else args.path_to_output + '.feather')
    MAX_WORDS = args.max_words

    words, track_ids, bows = load_json_data(path_to_data)

    if not args.keep_stopwords:
        nltk.download('stopwords')

        stop = stopwords.words('english')
        keys_to_remove = [str(idx) for idx, word in enumerate(words, 1) if word
                          in stop]
        removed = [w for w in words if w in stop]
        words = [word for word in words if word not in stop]

        logger.info('Removing stopwords: %s', removed)

        def remove_stop_indexes(bow):
            for key in keys_to_remove:
                bow.pop(key, None)

        for bow in bows:
            remove_stop_indexes(bow)

    words = words[:MAX_WORDS]

    # create matrix with all the songs and top words
    X = np.stack([bow2vector(bow, max_words=MAX_WORDS) for bow in bows], axis=0)
    X = X.astype('int16')

    if args.normalize:
        sums = X.sum(axis=1, keepdims=True)
        X = np.divide(X, sums, where=sums != 0)

    df = pd.DataFrame(X, columns=words)
    df.insert(0, 'track_id', track_ids)

    logger.info('Saving file in {}'.format(path_to_output))
    df.to_feather(path_to_output)


if __name__ == "__main__":
    main()
