#!/usr/bin/env python
"""
Generate data for interactive component, by default it only outputs
artists with at least 10 songs
"""
import json
import argparse
import logging
from scipy.spatial.distance import pdist, squareform
import pandas as pd


def sum_words(df, words):
    """Sum word columns in a DataFrame
    """
    sums = df[words].sum(axis=0)
    return sums


def top_k_words(artist, k=10):
    """Get top k words for an artist as {word: count} mapping
    """
    return artist.sort_values(ascending=False)[:k].to_dict()


def top_genres(artist, k=3):
    """Get list of top k genres
    """
    return list(artist.genre_
                      .value_counts()
                      .sort_values(ascending=False)[:k]
                      .index)


def songs_per_year(artist, k=3):
    """Get songs per year in a {year: count} mapping
    """
    d = artist.release_year_.value_counts().to_dict()
    return {int(k): v for k, v in d.items()}


def group_info(artist_name, mappings, new_keys):
    """Group artist info in a single mapping
    """
    d = {}

    for mapping, key in zip(mappings, new_keys):
        d[key] = mapping[artist_name]

    return d


def artist_distance(embeddings, dims):
    """
    Given an embeddings, return a DataFrame with the distances between
    artists
    """
    embeddings_only = embeddings.loc[:, ['artist_name_'] + dims]
    artist_vectors = embeddings_only.groupby('artist_name_').mean()

    dist = squareform(pdist(artist_vectors.values))
    distances = pd.DataFrame(dist, index=artist_vectors.index,
                             columns=artist_vectors.index)

    return distances


def most_similar_artists(artist_name, distance_matrix, k=10):
    return list(distance_matrix[artist_name].sort_values()[1:k+1].index)


def main():
    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)

    # use docstring at the top as description for the script
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument('path_to_bag_of_words', type=str,
                        help='Path to bag of words data')
    parser.add_argument('path_to_embeddings', type=str,
                        help='Path to embeddings data')
    parser.add_argument('path_to_profiles', type=str,
                        help='Path to output JSON file with artists profiles')
    parser.add_argument('path_to_artists', type=str,
                        help='Path to output JSON file with artist names')
    parser.add_argument('--min_songs', default=10, type=int,
                        help='Only output artists with this minimum number '
                             'of songs, defaults to three')

    args = parser.parse_args()
    path_to_bag_of_words = args.path_to_bag_of_words
    path_to_embeddings = args.path_to_embeddings
    path_to_profiles = args.path_to_profiles
    path_to_artists = args.path_to_artists
    min_songs = args.min_songs

    # load bag of words and embeddings
    logger.info('Loading data...')
    bow = pd.read_feather(path_to_bag_of_words)
    embeddings = pd.read_feather(path_to_embeddings)

    # filter artists: only keep the ones with >= min_songs songs
    n_songs_series = bow.groupby('artist_name_').apply(lambda df: df.shape[0])
    artists_to_keep = n_songs_series[n_songs_series > min_songs].index

    logger.info('Keeping only artists with at least %d songs: %d out of %d '
                '(%.2f %%)',
                min_songs, len(artists_to_keep), len(n_songs_series),
                100*len(artists_to_keep)/len(n_songs_series))

    bow = bow[bow.artist_name_.isin(artists_to_keep)]
    embeddings = embeddings[embeddings.artist_name_.isin(artists_to_keep)]

    # columns corresponding to metadata, word counts and embeddings dimensions
    words = [col for col in bow.columns if not col.endswith('_')]
    dims = [col for col in embeddings.columns if col.startswith('D')]

    # get list of unique artists
    artists = list(bow.artist_name_.unique())

    # top 5 songs for each artist
    logger.info('Finding top 5 songs...')
    top_5 = (bow.groupby('artist_name_')
             .apply(sum_words, words=words)
             .apply(top_k_words, axis=1)
             .to_dict())

    # number of songs per artist
    logger.info('Counting number of songs...')
    n_songs = n_songs_series.to_dict()

    # top 3 genres
    logger.info('Finding top 3 genres...')
    genres = (bow.groupby('artist_name_')
              .apply(top_genres)
              .to_dict())

    # songs per year
    logger.info('Counting songs per year...')
    years = (bow.groupby('artist_name_')
             .apply(songs_per_year)
             .to_dict())

    # find most similar artists
    logger.info('Finding similar artists...')
    distances = artist_distance(embeddings, dims=dims)
    similar = {artist: most_similar_artists(artist, distances)
               for artist in artists}

    # build dataset
    mappings = [top_5, n_songs, genres, years, similar]
    keys = ['top_words', 'n_songs', 'top_genres', 'years', 'similar_artists']
    data = {}

    logger.info('Generating output file...')

    for artist in artists:
        data[artist] = group_info(artist, mappings, keys)

    with open(path_to_profiles, 'w') as f:
        json.dump(data, f)

    with open(path_to_artists, 'w') as f:
        json.dump(artists, f)

    logger.info('Saved profiles in %s', path_to_profiles)
    logger.info('Saved artists list in %s', path_to_artists)


if __name__ == "__main__":
    main()
