#!/usr/bin/env python
"""
Generate data for interactive component, by default it only outputs
artists with at least 10 songs
"""
import argparse
import logging
from scipy.spatial.distance import pdist, squareform
import pandas as pd
import numpy as np


def sum_words(df, words):
    """Sum word columns in a DataFrame
    """
    sums = df[words].sum(axis=0)

    return sums


def top_k_words(artist, k=10):
    """Get top k words for an artist as {word: count} mapping
    """
    total = artist.sum()
    top_k = artist.sort_values(ascending=False)[:k].to_dict()

    return [{'word': word, 'count': count, 'proportion': count / total}
            for word, count in top_k.items()]


def top_genres(artist, k=3):
    """Get list of top k genres
    """
    return list(artist.genre_
                      .value_counts()
                      .sort_values(ascending=False)[:k]
                      .index)


def songs_per_year(artist, k=3):
    """Get songs per year in a {year: count} mapping
    """
    d = artist.release_year_.value_counts().to_dict()
    return {int(k): v for k, v in d.items()}


def group_info(artist_name, mappings, new_keys):
    """Group artist info in a single mapping
    """
    d = {}

    for mapping, key in zip(mappings, new_keys):
        d[key] = mapping[artist_name]

    d['artist'] = artist_name

    return d


def artist_distance(embeddings, dims):
    """
    Given an embeddings, return a DataFrame with the distances between
    artists
    """
    embeddings_only = embeddings.loc[:, ['artist_name_'] + dims]
    artist_vectors = embeddings_only.groupby('artist_name_').mean()

    dist = squareform(pdist(artist_vectors.values))
    distances = pd.DataFrame(dist, index=artist_vectors.index,
                             columns=artist_vectors.index)

    return distances


def most_similar_artists(artist_name, distance_matrix, k=10):
    return list(distance_matrix[artist_name].sort_values()[1:k+1].index)


def main():
    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)

    # use docstring at the top as description for the script
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument('path_to_bag_of_words', type=str,
                        help='Path to bag of words data')
    parser.add_argument('path_to_embeddings', type=str,
                        help='Path to embeddings data')
    parser.add_argument('path_to_artist_topics', type=str,
                        help='Path to artist topics file')
    parser.add_argument('path_to_sentiment', type=str,
                        help='Path to mean sentiment data')
    parser.add_argument('path_to_profiles', type=str,
                        help='Path to output CSV file with artists profiles')
    parser.add_argument('--min_songs', default=10, type=int,
                        help='Only output artists with this minimum number '
                             'of songs, defaults to three')

    args = parser.parse_args()
    path_to_bag_of_words = args.path_to_bag_of_words
    path_to_embeddings = args.path_to_embeddings
    path_to_artist_topics = args.path_to_artist_topics
    path_to_sentiment = args.path_to_sentiment
    path_to_profiles = args.path_to_profiles
    min_songs = args.min_songs

    # load bag of words and embeddings
    logger.info('Loading data...')
    bow = pd.read_feather(path_to_bag_of_words)
    embeddings = pd.read_feather(path_to_embeddings)

    # filter artists: only keep the ones with >= min_songs songs
    n_songs_series = bow.groupby('artist_name_').apply(lambda df: df.shape[0])
    artists_to_keep = n_songs_series[n_songs_series > min_songs].index

    logger.info('Keeping only artists with at least %d songs: %d out of %d '
                '(%.2f %%)',
                min_songs, len(artists_to_keep), len(n_songs_series),
                100*len(artists_to_keep)/len(n_songs_series))

    bow = bow[bow.artist_name_.isin(artists_to_keep)]
    embeddings = embeddings[embeddings.artist_name_.isin(artists_to_keep)]

    # columns corresponding to metadata, word counts and embeddings dimensions
    words = [col for col in bow.columns if not col.endswith('_')]
    dims = [col for col in embeddings.columns if col.startswith('D')]

    # get list of unique artists
    artists = list(bow.artist_name_.unique())

    # top 5 songs for each artist
    logger.info('Finding top 5 songs...')
    top_5 = (bow.groupby('artist_name_')
             .apply(sum_words, words=words)
             .apply(top_k_words, axis=1)
             .to_dict())

    # number of songs per artist
    logger.info('Counting number of songs...')
    n_songs = n_songs_series.to_dict()

    # top 3 genres
    logger.info('Finding top 3 genres...')
    genres = (bow.groupby('artist_name_')
              .apply(top_genres)
              .to_dict())

    # songs per year
    logger.info('Counting songs per year...')
    years = (bow.groupby('artist_name_')
             .apply(songs_per_year)
             .to_dict())

    def _safe(fn, l):
        return np.nan if not l else fn(l)

    years_start = {artist: _safe(min, years.keys()) for artist, years
                   in years.items()}

    years_end = {artist: _safe(max, years.keys()) for artist, years
                 in years.items()}

    # find most similar artists
    logger.info('Finding similar artists...')
    distances = artist_distance(embeddings, dims=dims)
    similar = {artist: most_similar_artists(artist, distances)
               for artist in artists}

    # build dataset
    mappings = [top_5, n_songs, genres, years, similar, years_start, years_end]
    keys = ['words', 'songs', 'genres', 'years', 'similar', 'year_st',
            'year_end']

    data = []

    logger.info('Generating output file...')

    for artist in artists:
        data.append(group_info(artist, mappings, keys))

    df = pd.DataFrame(data)

    # add topic
    logger.info('Adding topic...')
    topics = pd.read_feather(path_to_artist_topics)
    topics = topics[['artist_name', 'love', 'death', 'religion']]
    df = df.merge(topics, left_on='artist', right_on='artist_name')

    # add sentiment
    logger.info('Adding sentiment...')
    sentiment = pd.read_feather(path_to_sentiment)
    df = df.merge(sentiment, on='artist_id')

    nas = df.apply(lambda c: np.sum(c.isna()), axis=0) / df.shape[0] * 100
    logger.info('NA stats: {}'.format(nas))

    df.to_csv(path_to_profiles, index=False)

    logger.info('Saved profiles in %s', path_to_profiles)


if __name__ == "__main__":
    main()
