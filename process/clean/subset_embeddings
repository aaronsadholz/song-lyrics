#!/usr/bin/env python

"""
GLOVE contains 400K words and our dataset only 5K, we need to subset GLOVE
so it loads faster, also, some words do not match so we need to do entity
resolution
"""
from pathlib import Path
import json
import logging
import logging.config
import argparse
from song_lyrics.parse import load_json_data, glovetxt2dict
from song_lyrics.resolution import match
from song_lyrics.util import load_logging_config_file


def main():
    # use docstring at the top as description for the script
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument('path_to_data', type=str,
                        help='Path to the txt data')
    parser.add_argument('path_to_glove', type=str,
                        help='Path to glove txt data')
    parser.add_argument('path_to_output', type=str,
                        help='Output json path')

    args = parser.parse_args()

    path_to_data = args.path_to_data
    path_to_glove = args.path_to_glove
    path_to_output = args.path_to_output

    logging_config = load_logging_config_file()

    folder = Path(path_to_output).parent
    filename = '{}.log'.format(Path(__file__).name)
    logging_config['handlers']['file']['filename'] = str(folder / filename)

    logging.config.dictConfig(logging_config)

    logger = logging.getLogger(__name__)

    logger.info('Log will be saved at: {}'.format(str(folder / filename)))

    # load word embeddings
    logger.info('Loading GLOVE from: {}'.format(path_to_glove))
    glove = glovetxt2dict(path_to_glove)

    # parse json data
    logger.info('Loading Musixmatch data from {}'.format(path_to_data))
    words, track_ids, bows = load_json_data(path_to_data)

    words_glove = set(glove.keys())
    words_data = set(words)

    logger.info('GLOVE contains {:,} words'.format(len(words_glove)))
    logger.info('Musixmatch contains {:,} words'.format(len(words_data)))

    # first find exact matches
    both = words_data & words_glove
    # now find the ones missing (we need to match this)
    to_match = words_data - both

    logger.info('Exact matches: {:,}'.format(len(both)))
    logger.info('To match: {:,}'.format(len(to_match)))

    # build subset with exact matches
    subset = {k: v for k, v in glove.items() if k in both}

    words_glove_sorted = sorted(list(words_glove))

    mapping = match(list(to_match), words_glove_sorted)

    subset_matched = {k: glove[v] for k, v in mapping.items() if v is not None}

    non_matched = [k for k, v in mapping.items() if v is None]
    logger.info('Non matches: {}'.format(non_matched))

    res = {**subset, **subset_matched}

    logger.info('Final vocabulary size {:,}, failed to match {:,}'
                .format(len(res), len(to_match) - len(subset_matched)))

    logger.info('Writing to disk...')

    with open(path_to_output, 'w') as f:
        json.dump(res, f)

    logger.info('Output saved in {}'.format(path_to_output))


if __name__ == "__main__":
    main()
